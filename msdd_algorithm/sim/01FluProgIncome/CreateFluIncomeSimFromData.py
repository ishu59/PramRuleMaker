import os,sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))  # 'rules' module
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))
from SequenceGenerator import SequenceGenerator
from algorithm import msdd_algorithm_simple, clean_data

def create_income_sir_data(transition_lower=None, transition_upper=None, sample_size = 5000):
    # A Dynamic Bayesian net.
    #
    # Initial state distribution:
    #     flu: (1 0 0)
    #     income: (0.5 0.5)
    #
    # Transition model:
    #                 L                    M
    #           S     I     R        S     I     R
    #     S  0.90  0.00  0.20     0.95  0.00  0.10
    #     I  0.10  0.75  0        0.05  0.50  0
    #     R  0     0.25  0.80     0     0.50  0.90

    # transition_lower = {'S': {'S': 0.7, 'I': 0.3, 'R': 0}, 'I': {'S': 0, 'I': 0.5, 'R': 0.5},
    #               'R': {'S': 0.3, 'I': 0.0, 'R': 0.7}}
    transition_lower = {'S': {'S': 0.9, 'I': 0.1, 'R': 0}, 'I': {'S': 0, 'I': 0.75, 'R': 0.25},
                        'R': {'S': 0.2, 'I': 0, 'R': 0.8}}
    SIR = SequenceGenerator(transition_prob=transition_lower)
    sequence_data = SIR.generate_states(current_state='S', nt=sample_size)
    with open('data/sir_lower_income.txt','w') as file:
        for item in sequence_data:
            file.writelines('{},'.format(item))

    transition_upper = {'S': {'S': 0.95, 'I': 0.05, 'R': 0}, 'I': {'S': 0, 'I': 0.5, 'R': 0.5},
                        'R': {'S': 0.1, 'I': 0.0, 'R': 0.9}}
    SIR = SequenceGenerator(transition_prob=transition_upper)
    sequence_data = SIR.generate_states(current_state='S', nt=sample_size)
    with open('data/sir_middle_income.txt', 'w') as file:
        for item in sequence_data:
            file.writelines('{},'.format(item))

def read_data_lower_middle_SIR():
    with open('data/sir_lower_income.txt', 'r') as file:
        l = file.readlines()
    # print(l[0].split(','))
    l = l[0].split(',')
    l = clean_data(l)
    with open('data/sir_middle_income.txt', 'r') as file:
        m = file.readlines()
    # print(m[0].split(','))
    m = m[0].split(',')
    m = clean_data(m)
    return l,m

def generate_class_from_rule_dict_large(rule_dict,class_index = 1, has_attr =['income','flu'], set_attr = ['flu']):
    imp_str = '''import sys
sys.path.append('/home/ishu/Documents/res-work/prams/pram/src')
print(sys.path)
'''
    import_str =imp_str + "from pram.data   import GroupSizeProbe, ProbeMsgMode\nfrom pram.entity import Group, GroupQry, GroupSplitSpec, Site\nfrom pram.rule   import GoToRule, DiscreteInvMarkovChain, TimeInt, Rule\nfrom pram.sim    import Simulation\n\n\n"
    rule_string = "class Autogenerated{}(Rule):\n\tdef apply(self, pop, group, iter, t):\n\t\t".format(class_index)
    rule_string = import_str + rule_string
    # for item in has_attr:
    condition_string_a = "\t\tif group.has_attr({'" + has_attr[0] + "': '"
    condition_string_b = "'}):\n"
    condition_string = "\t\t\tif group.has_attr({'"+has_attr[1] +"': "
    condition_string_2 = "}): return ["
    g_spec_str_1 = "GroupSplitSpec(p= "
    g_spec_str_2 = ", attr_set={ '"+set_attr[0]+"': "
    g_spec_str_3 = " }),"
    condition_string_3 = "]\n"
    for uu_index, (uu_key, uu_val) in enumerate(rule_dict.items()):
        urs = condition_string_a + uu_key + condition_string_b
        for upper_index, (key, val) in enumerate(uu_val.items()):
            if len(key) < 2:
                rs =urs + condition_string +"'" + key[0] + "'" + condition_string_2
            else:
                rs = urs+condition_string + str(key) + condition_string_2

            for i, (child_key, child_val) in enumerate(val.items()):
                p_minus = 0
                if i > len(val) - 1:
                    p = p_minus
                else:
                    p = child_val
                    p_minus += p
                print(type(child_key))
                if len(child_key) < 2:
                    rss = g_spec_str_1 + str(p) + g_spec_str_2 +"'"+ child_key[0] +"'"+ g_spec_str_3
                elif type(child_key) == 'str' or type(child_key == 'numpy.str_'):
                    rss = g_spec_str_1 + str(p) + g_spec_str_2 + "'" + child_key + "'" + g_spec_str_3
                else:
                    rss = g_spec_str_1 + str(p) + g_spec_str_2 + str(child_key) + g_spec_str_3
                rs += rss
            rs += condition_string_3
            rule_string = rule_string + '\n' + rs

    print(rule_string)
    new_file_name = 'Autogenerated{}.py'.format(class_index)
    with open(new_file_name, 'w') as file:
        file.writelines(rule_string)


def generate_flu_income_rule_from_data():
    lower_seq_data, middle_seq_data = read_data_lower_middle_SIR()
    lower_rule_dict = msdd_algorithm_simple(lower_seq_data, precursor_width= 1, sucessor_width= 1, lagtime_between=1,
                                            dependency_evaluator_fn = None, num_rules = None)
    middle_rule_dict = msdd_algorithm_simple(middle_seq_data, precursor_width=1, sucessor_width=1, lagtime_between=1,
                                            dependency_evaluator_fn=None, num_rules=None)
    rule_dict = dict(l = lower_rule_dict, m = middle_rule_dict)
    # for rule_key, rule_val in rule_dict.items():
    #     generate_class_from_rule_dict_large(rule_val,rule_key)
    generate_class_from_rule_dict_large(rule_dict)

if __name__ == '__main__':
    # create_income_sir_data()
    # lower, middle = read_data_lower_middle_SIR()
    # print(lower)
    # print(middle)
    # pass
    generate_flu_income_rule_from_data()